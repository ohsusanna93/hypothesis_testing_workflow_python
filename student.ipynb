{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mod 3 Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Student Info\n",
    "\n",
    "- Name: Susanna Han\n",
    "- Cohort: Part Time\n",
    "- Instructor: James\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instructions:"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- Open and read the project assignment and guidelines in `MOD_PROJECT_README.ipynb`\n",
    "- Review the hypothesis testing workflow found in this repo's `README.md` and inside `hypothesis_testing_workflow.ipynb` (also at the bottom of the `MOD_PROJECT_README.ipynb`)\n",
    "\n",
    "- 3 functions from study group/learn.co lessons have been provided inside `functions.py`\n",
    "    - `Cohen_d`, `find_outliers_IQR`,`find_outliers_Z`"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-mod-3-project-online-ds-ft-100719/master/Northwind_ERD_updated.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U fsds_100719\n",
    "from fsds_100719.imports import *\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cohen_d(group1, group2, correction = False):\n",
    "    \"\"\"Compute Cohen's d\n",
    "    d = (group1.mean()-group2.mean())/pool_variance.\n",
    "    pooled_variance= (n1 * var1 + n2 * var2) / (n1 + n2)\n",
    "\n",
    "    Args:\n",
    "        group1 (Series or NumPy array): group 1 for calculating d\n",
    "        group2 (Series or NumPy array): group 2 for calculating d\n",
    "        correction (bool): Apply equation correction if N<50. Default is False. \n",
    "            - Url with small ncorrection equation: \n",
    "                - https://www.statisticshowto.datasciencecentral.com/cohens-d/ \n",
    "    Returns:\n",
    "        d (float): calculated d value\n",
    "         \n",
    "    INTERPRETATION OF COHEN's D: \n",
    "    > Small effect = 0.2\n",
    "    > Medium Effect = 0.5\n",
    "    > Large Effect = 0.8\n",
    "    \n",
    "    \"\"\"\n",
    "    import scipy.stats as stats\n",
    "    import scipy   \n",
    "    import numpy as np\n",
    "    N = len(group1)+len(group2)\n",
    "    diff = group1.mean() - group2.mean()\n",
    "\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    var1 = group1.var()\n",
    "    var2 = group2.var()\n",
    "\n",
    "    # Calculate the pooled threshold as shown earlier\n",
    "    pooled_var = (n1 * var1 + n2 * var2) / (n1 + n2)\n",
    "    \n",
    "    # Calculate Cohen's d statistic\n",
    "    d = diff / np.sqrt(pooled_var)\n",
    "    \n",
    "    ## Apply correction if needed\n",
    "    if (N < 50) & (correction==True):\n",
    "        d=d * ((N-3)/(N-2.25))*np.sqrt((N-2)/N)\n",
    "    return d\n",
    "\n",
    "\n",
    "#Your code here\n",
    "def find_outliers_z(data):\n",
    "    \"\"\"Use scipy to calculate absolute Z-scores \n",
    "    and return boolean series where True indicates it is an outlier.\n",
    "\n",
    "    Args:\n",
    "        data (Series,or ndarray): data to test for outliers.\n",
    "\n",
    "    Returns:\n",
    "        [boolean Series]: A True/False for each row use to slice outliers.\n",
    "        \n",
    "    EXAMPLE USE: \n",
    "    >> idx_outs = find_outliers_df(df['AdjustedCompensation'])\n",
    "    >> good_data = df[~idx_outs].copy()\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import scipy.stats as stats\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    ## Calculate z-scores\n",
    "    zs = stats.zscore(data)\n",
    "    \n",
    "    ## Find z-scores >3 awayfrom mean\n",
    "    idx_outs = np.abs(zs)>3\n",
    "    \n",
    "    ## If input was a series, make idx_outs index match\n",
    "    if isinstance(data,pd.Series):\n",
    "        return pd.Series(idx_outs,index=data.index)\n",
    "    else:\n",
    "        return pd.Series(idx_outs)\n",
    "    \n",
    "    \n",
    "    \n",
    "def find_outliers_IQR(data):\n",
    "    \"\"\"Use Tukey's Method of outlier removal AKA InterQuartile-Range Rule\n",
    "    and return boolean series where True indicates it is an outlier.\n",
    "    - Calculates the range between the 75% and 25% quartiles\n",
    "    - Outliers fall outside upper and lower limits, using a treshold of  1.5*IQR the 75% and 25% quartiles.\n",
    "\n",
    "    IQR Range Calculation:    \n",
    "        res = df.describe()\n",
    "        IQR = res['75%'] -  res['25%']\n",
    "        lower_limit = res['25%'] - 1.5*IQR\n",
    "        upper_limit = res['75%'] + 1.5*IQR\n",
    "\n",
    "    Args:\n",
    "        data (Series,or ndarray): data to test for outliers.\n",
    "\n",
    "    Returns:\n",
    "        [boolean Series]: A True/False for each row use to slice outliers.\n",
    "        \n",
    "    EXAMPLE USE: \n",
    "    >> idx_outs = find_outliers_df(df['AdjustedCompensation'])\n",
    "    >> good_data = df[~idx_outs].copy()\n",
    "    \n",
    "    \"\"\"\n",
    "    df_b=data\n",
    "    res= df_b.describe()\n",
    "\n",
    "    IQR = res['75%'] -  res['25%']\n",
    "    lower_limit = res['25%'] - 1.5*IQR\n",
    "    upper_limit = res['75%'] + 1.5*IQR\n",
    "\n",
    "    idx_outs = (df_b>upper_limit) | (df_b<lower_limit)\n",
    "\n",
    "    return idx_outs\n",
    "\n",
    "\n",
    "\n",
    "def prep_data_for_tukeys(data):\n",
    "    \"\"\"Accepts a dictionary with group names as the keys \n",
    "    and pandas series as the values. \n",
    "    \n",
    "    Returns a dataframe ready for tukeys test:\n",
    "    - with a 'data' column and a 'group' column for sms.stats.multicomp.pairwise_tukeyhsd \n",
    "    \n",
    "    Example Use:\n",
    "    df_tukey = prep_data_for_tukeys(grp_data)\n",
    "    tukey = sms.stats.multicomp.pairwise_tukeyhsd(df_tukey['data'], df_tukey['group'])\n",
    "    tukey.summary()\n",
    "    \"\"\"\n",
    "    \n",
    "    df_tukey = pd.DataFrame(columns=['data','group'])\n",
    "    for k,v in  data.items():\n",
    "        grp_df = v.rename('data').to_frame() \n",
    "        grp_df['group'] = k\n",
    "        df_tukey=pd.concat([df_tukey, grp_df],axis=0)\n",
    "\n",
    "\t## New lines added to ensure compatibility with tukey's test\n",
    "    df_tukey['group'] = df_tukey['group'].astype('str')\n",
    "    df_tukey['data'] = df_tukey['data'].astype('float')\n",
    "    return df_tukey\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "connect = sqlite3.connect('Northwind_small.sqlite')\n",
    "cur = connect.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To see all tables\n",
    "cur.execute(\"\"\"SELECT name FROM sqlite_master WHERE type='table';\"\"\")\n",
    "df_tables = pd.DataFrame(cur.fetchall(), columns=['Table'])\n",
    "df_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis 1"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "> Does discount amount have a statistically significant effect on the quantity of a product in an order? If so, at what level(s) of discount?\n",
    "\n",
    "- $H_0$: The customer orders the same quantity of a product whether it's discounted or full price. \n",
    "- $H_A$: The customer orders more or less of a product whether it's discounted or full price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('''SELECT * from OrderDetail''')\n",
    "col_names = [x[0] for x in cur.description]\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(cur.fetchall(), columns = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Discount'] = df['Discount'] > 0\n",
    "df['Discount'] = df['Discount'].map({True:'Discounted', False: 'Full Price'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=df, x = df['Discount'], y= df['Quantity'], ci=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discounts = {}\n",
    "for discount_grps in df['Discount'].unique():\n",
    "    discounts[discount_grps]= df.groupby('Discount').get_group(discount_grps)['Quantity']\n",
    "discounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize = (8,5))\n",
    "for discount_grps, grp_data in discounts.items():\n",
    "    sns.distplot(grp_data, label=discount_grps, ax=ax)\n",
    "ax.legend()\n",
    "ax.set(title ='Quantity by Discounted Group', ylabel = 'Density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for discount_grps, grp_data in discounts.items():\n",
    "    idx_outs = find_outliers_z(grp_data)\n",
    "    print(f'[I] found {idx_outs.sum()} outliers in {discount_grps} using z-scores')\n",
    "    discounts[discount_grps] = grp_data[-idx_outs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize = (8,5))\n",
    "for discount_grps, grp_data in discounts.items():\n",
    "    sns.distplot(grp_data, label=discount_grps, ax=ax )\n",
    "ax.legend()\n",
    "ax.set(title ='Quantity by Discounted Group', ylabel = 'Density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in discounts.items():\n",
    "    stat,p = stats.normaltest(v)\n",
    "    print(f\"The {k} Normaltest p-value = {round(p,4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {len(discounts['Full Price'])} full price items.\")\n",
    "print(f\"There are {len(discounts['Discounted'])} discounted items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beause the p-value is < 0.05 the data is not normal but since the size of our data is big enough we can ignore the results of the normal test.\n",
    "#Now we will test for equal variance by using the levene's test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for k,v in discounts.items():\n",
    "    data.append(v)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.levene(*data) "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis 2"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "> Does discount have a statistically significant effect on the total amount spent in an order? \n",
    "\n",
    "- $H_0$: The customer spends the same amount of money whether it's discounted or full price. \n",
    "- $H_A$: The customer spends more or less money whether it's discounted or full price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Total Spent'] = df['UnitPrice'] * df['Quantity']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=df, x = df['Discount'], y= df['Total Spent'], ci=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at the bar graph we can see that the discounted products have a larger spending amount than the full priced items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discounts = {}\n",
    "for discount_grps in df['Discount'].unique():\n",
    "    discounts[discount_grps]= df.groupby('Discount').get_group(discount_grps)['Total Spent']\n",
    "discounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize = (8,5))\n",
    "for discount_grps, grp_data in discounts.items():\n",
    "    sns.distplot(grp_data, label=discount_grps, ax=ax )\n",
    "ax.legend()\n",
    "ax.set(title ='Total Spent by Discounted Group', ylabel = 'Density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for discount_grps, grp_data in discounts.items():\n",
    "    idx_outs = find_outliers_z(grp_data)\n",
    "    print(f'[I] found {idx_outs.sum()} outliers in {discount_grps} using z-scores')\n",
    "    discounts[discount_grps] = grp_data[-idx_outs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize = (8,5))\n",
    "for discount_grps, grp_data in discounts.items():\n",
    "    sns.distplot(grp_data, label=discount_grps, ax=ax )\n",
    "ax.legend()\n",
    "ax.set(title ='Total Spent by Discounted Group', ylabel = 'Density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in discounts.items():\n",
    "    stat,p = stats.normaltest(v)\n",
    "    print(f\"The {k} Normaltest p-value = {round(p,4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {len(discounts['Full Price'])} full price items.\")\n",
    "print(f\"There are {len(discounts['Discounted'])} discounted items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for k,v in discounts.items():\n",
    "    data.append(v)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats,p = stats.levene(*data) \n",
    "print(f'Levenes test for equal variance p-value ={round(p,4)} therefore it does not have equal variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis 3"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "> Does the supplier region have a statistically significant effect on the product quantity sold.\n",
    "\n",
    "- $H_0$: The supplier region does not have an effect on the product quantity sold.\n",
    "- $H_A$: THe supplier region does have an effect on the product quantity sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('''SELECT *\n",
    "               FROM Supplier\n",
    "               JOIN Product\n",
    "               JOIN OrderDetail;''')\n",
    "df = pd.DataFrame(cur.fetchall()) \n",
    "col_names = [x[0] for x in cur.description]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(cur.fetchall(), columns = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discounts = {}\n",
    "for discount_grps in df['Discount'].unique():\n",
    "    discounts[discount_grps]= df.groupby('Discount').get_group(discount_grps)['Quantity']\n",
    "discounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=df, x = df['Region'], y= df['Quantity'], ci=68)\n",
    "region - product id - Quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis 4"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "> Does the customer region have a statistically significant effect on the number of sales?\n",
    "\n",
    "- $H_0$:\n",
    "- $H_A$:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}